"""
Mofy Agent Framework - ReActèŒƒå¼Agentç¤ºä¾‹
å±•ç¤ºæ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿçš„å¾ªç¯æ¨¡å¼
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.agent import create_agent
from modules.tools.builtin import register_builtin_tools
from core.llm import llm_client

class ReActAgent:
    """ReActèŒƒå¼çš„Agent"""
    
    def __init__(self, session_id: str = None):
        self.agent = create_agent(session_id)
        self.max_iterations = 5
    
    async def solve(self, problem: str) -> str:
        """ä½¿ç”¨ReActæ¨¡å¼è§£å†³é—®é¢˜"""
        print(f"ğŸ¤” é—®é¢˜: {problem}")
        print("=" * 50)
        
        context = ""
        for iteration in range(self.max_iterations):
            print(f"\nğŸ“ æ­¥éª¤ {iteration + 1}:")
            
            # æ€è€ƒé˜¶æ®µ
            thought = await self._think(problem, context)
            print(f"ğŸ’­ æ€è€ƒ: {thought}")
            
            # è¡ŒåŠ¨é˜¶æ®µ
            action = await self._act(thought)
            print(f"ğŸ¬ è¡ŒåŠ¨: {action}")
            
            # è§‚å¯Ÿé˜¶æ®µ
            observation = await self._observe(action)
            print(f"ğŸ‘€ è§‚å¯Ÿ: {observation}")
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context += f"\næ­¥éª¤{iteration + 1}:\næ€è€ƒ: {thought}\nè¡ŒåŠ¨: {action}\nè§‚å¯Ÿ: {observation}\n"
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if await self._is_complete(problem, observation):
                final_answer = await self._generate_final_answer(problem, context)
                print(f"\nâœ… æœ€ç»ˆç­”æ¡ˆ: {final_answer}")
                return final_answer
        
        return "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œæœªèƒ½å®Œå…¨è§£å†³é—®é¢˜"
    
    async def _think(self, problem: str, context: str) -> str:
        """æ€è€ƒé˜¶æ®µ"""
        prompt = f"""é—®é¢˜: {problem}
ä¹‹å‰çš„æ­¥éª¤: {context}

è¯·åˆ†æå½“å‰æƒ…å†µï¼Œå†³å®šä¸‹ä¸€æ­¥åº”è¯¥é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ã€‚æ€è€ƒè¿‡ç¨‹åº”è¯¥ç®€çŸ­æ˜ç¡®ã€‚
è¾“å‡ºæ ¼å¼: {{
    "thought": "ä½ çš„æ€è€ƒå†…å®¹",
    "next_action": "ä¸‹ä¸€æ­¥è¡ŒåŠ¨æè¿°"
}}
"""
        
        response = llm_client.invoke(prompt)
        parsed = llm_client.parse_response(response)
        return parsed.get("thought", "ç»§ç»­åˆ†æé—®é¢˜")
    
    async def _act(self, thought: str) -> str:
        """è¡ŒåŠ¨é˜¶æ®µ"""
        prompt = f"""åŸºäºä»¥ä¸‹æ€è€ƒï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·æˆ–ç›´æ¥å›ç­”:
æ€è€ƒ: {thought}

å¯ç”¨å·¥å…·:
- calculator: æ•°å­¦è®¡ç®—
- search: ç½‘ç»œæœç´¢  
- weather: å¤©æ°”æŸ¥è¯¢

è¾“å‡ºæ ¼å¼: {{
    "action": "tool_call|direct_answer",
    "tool": "å·¥å…·åç§°",
    "parameters": {{"å‚æ•°": "å€¼"}},
    "response": "ç›´æ¥å›ç­”å†…å®¹"
}}
"""
        
        response = llm_client.invoke(prompt)
        parsed = llm_client.parse_response(response)
        
        if parsed.get("action") == "tool_call":
            tool_name = parsed.get("tool")
            parameters = parsed.get("parameters", {})
            
            # æ‰§è¡Œå·¥å…·
            from modules.tools import tool_registry
            params_str = str(parameters) if isinstance(parameters, dict) else parameters
            result = tool_registry.execute_tool(tool_name, params_str)
            return f"ä½¿ç”¨{tool_name}å·¥å…·: {result}"
        else:
            return parsed.get("response", "ç›´æ¥å›ç­”")
    
    async def _observe(self, action_result: str) -> str:
        """è§‚å¯Ÿé˜¶æ®µ"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ å¯¹è¡ŒåŠ¨ç»“æœçš„åˆ†æ
        if "æ‰§è¡Œå¤±è´¥" in action_result:
            return "è¡ŒåŠ¨å¤±è´¥ï¼Œéœ€è¦è°ƒæ•´ç­–ç•¥"
        elif "è®¡ç®—ç»“æœ" in action_result or "æœç´¢ç»“æœ" in action_result:
            return "è¡ŒåŠ¨æˆåŠŸï¼Œè·å¾—æœ‰ç”¨ä¿¡æ¯"
        else:
            return "è¡ŒåŠ¨å®Œæˆ"
    
    async def _is_complete(self, problem: str, observation: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å®Œæˆ"""
        prompt = f"""é—®é¢˜: {problem}
æœ€æ–°è§‚å¯Ÿ: {observation}

é—®é¢˜æ˜¯å¦å·²ç»å®Œå…¨è§£å†³ï¼Ÿå›ç­”"æ˜¯"æˆ–"å¦"ã€‚
"""
        
        response = llm_client.invoke(prompt)
        return "æ˜¯" in response
    
    async def _generate_final_answer(self, problem: str, context: str) -> str:
        """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
        prompt = f"""åŸºäºä»¥ä¸‹æ€è€ƒè¿‡ç¨‹ï¼Œä¸ºé—®é¢˜æä¾›æœ€ç»ˆç­”æ¡ˆ:
é—®é¢˜: {problem}
å®Œæ•´è¿‡ç¨‹: {context}

è¯·æä¾›æ¸…æ™°ã€å‡†ç¡®çš„æœ€ç»ˆç­”æ¡ˆã€‚
"""
        
        return llm_client.invoke(prompt)

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– Mofy Agent Framework - ReActèŒƒå¼ç¤ºä¾‹")
    print("=" * 50)
    
    # æ³¨å†Œå†…ç½®å·¥å…·
    register_builtin_tools()
    
    # åˆ›å»ºReAct Agent
    agent = ReActAgent("react_demo")
    
    # ç¤ºä¾‹é—®é¢˜
    problems = [
        "è®¡ç®— 123 + 456 * 789 çš„ç»“æœ",
        "æŸ¥è¯¢åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µ",
        "æœç´¢äººå·¥æ™ºèƒ½çš„æœ€æ–°å‘å±•"
    ]
    
    print("è¯·é€‰æ‹©è¦è§£å†³çš„é—®é¢˜:")
    for i, problem in enumerate(problems, 1):
        print(f"{i}. {problem}")
    print("4. è‡ªå®šä¹‰é—®é¢˜")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
    
    if choice == "4":
        problem = input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
    elif choice in ["1", "2", "3"]:
        problem = problems[int(choice) - 1]
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤é—®é¢˜")
        problem = problems[0]
    
    # è§£å†³é—®é¢˜
    await agent.solve(problem)

if __name__ == "__main__":
    asyncio.run(main())